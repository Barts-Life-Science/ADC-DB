{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "179a8631-cabf-461c-855c-efa9d984353e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Notebook parameters\n",
    "\n",
    "params = {\n",
    "    \"proj_dir\": \"\",\n",
    "}\n",
    "\n",
    "# create text widgets\n",
    "for k in params.keys():\n",
    "    dbutils.widgets.text(k, \"\", \"\")\n",
    "\n",
    "# fetch values\n",
    "for k in params.keys():\n",
    "    params[k] = dbutils.widgets.get(k)\n",
    "    print(k, \":\", params[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8f70d1a-7c35-448e-a362-57176a61304e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.fileshare import ShareServiceClient\n",
    "import os\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "import asyncio\n",
    "from delta.tables import *\n",
    "import time\n",
    "import pydicom\n",
    "from functools import lru_cache\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d4dd2ae-e7b1-46fc-adc2-6ee5eb89b8e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sectra_dir = \"/Volumes/1_inland/sectra/vone/\"\n",
    "proj_dir_path = f\"{sectra_dir}/{params['proj_dir']}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a1980a6-8650-45a2-96f2-5ea788746975",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read DICOMDIR\n",
    "dicomdir = pydicom.dcmread(f\"{sectra_dir}/{params['proj_dir']}/DICOMDIR\")\n",
    "\n",
    "\n",
    "seq_len = len(dicomdir.DirectoryRecordSequence)\n",
    "batch_size = 5000\n",
    "max_iter = ceil(seq_len/batch_size)\n",
    "\n",
    "# Define schema for loading DICOMDIR\n",
    "schema = T.StructType([\n",
    "        T.StructField(\"subdirs\", T.StringType(), True),\n",
    "        T.StructField(\"filename\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "print(\"Start loop\")\n",
    "\n",
    "# Use batch processing to avoid \"maximum recursion depth exceeded\" error\n",
    "for iter_ind in tqdm.tqdm(range(max_iter)):\n",
    "    i = iter_ind*batch_size\n",
    "    j = min(i+batch_size, seq_len)\n",
    "\n",
    "    # Create an empty data frame\n",
    "    df = spark.createDataFrame(data = [], schema = schema)\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for x in dicomdir.DirectoryRecordSequence[i:j]:\n",
    "\n",
    "        # Retrieve ReferencedFileID which contains dcm file path info if exists\n",
    "        try:\n",
    "            refFileID = x[\"ReferencedFileID\"].value\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        data.append((f\"{refFileID[1]}/{refFileID[2]}\", refFileID[3]))\n",
    "\n",
    "    # Add source subdirs and dcm files\n",
    "    df = spark.createDataFrame(\n",
    "        data=data,\n",
    "        schema=schema\n",
    "    )\n",
    "\n",
    "    # Add destination file paths\n",
    "    df = df.withColumn(\"filepath\", F.concat(F.lit(sectra_dir), F.lit(params['proj_dir']), F.lit(\"/\"), F.col(\"subdirs\"), F.lit(\"/\"), F.col(\"filename\")))\n",
    "\n",
    "    df.createOrReplaceTempView(\"temp_new_files\")\n",
    "\n",
    "    # Insert dcm file paths to table\n",
    "    spark.sql(f\"\"\"\n",
    "    INSERT INTO 1_inland.sectra.pacs_file_process\n",
    "    (file_path, proj_dir, subdirs, filename, \n",
    "    added_at, file_status, file_status_updt_dt, \n",
    "    priority, active_ind\n",
    "    )\n",
    "    SELECT\n",
    "    filepath,'{params[\"proj_dir\"]}',subdirs, filename,\n",
    "    current_timestamp(), 'new', current_timestamp(),\n",
    "    0, 1\n",
    "    FROM temp_new_files\n",
    "    \"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d6c1d6f2-5d3e-4ca9-bae8-4f77ad3c3fe3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f354e143-404c-4ba9-8eb2-eb2f0a6ad7bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6075347534846593,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "add_files_for_processing",
   "widgets": {
    "proj_dir": {
     "currentValue": "test_azcopy",
     "nuid": "09a69732-bf64-466f-add1-ef9e5e8e1a12",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "proj_dir",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "proj_dir",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "src_proj_dir": {
     "currentValue": "",
     "nuid": "458c8b0c-9344-4295-826a-040f9b11f98a",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": "",
      "name": "src_proj_dir",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": "",
      "name": "src_proj_dir",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
