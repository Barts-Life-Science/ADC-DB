{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94e3e004-20d4-4035-8e60-ca96bb4862b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from azure.storage.fileshare import ShareServiceClient\n",
    "import os\n",
    "import pydicom\n",
    "from io import BytesIO\n",
    "from pydicom.fileset import FileSet\n",
    "import pandas as pd\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c1e0ff1-a65c-4c42-968f-bcf43a6c6e34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "acc_name = dbutils.secrets.get(scope = \"adc_store\", key = \"pacs_intfileshare_accname\")\n",
    "acc_key = dbutils.secrets.get(scope = \"adc_store\", key = \"pacs_intfileshare_acckey\")\n",
    "\n",
    "# Connection string\n",
    "connection_string = f\"DefaultEndpointsProtocol=https;AccountName={acc_name};AccountKey={acc_key};EndpointSuffix=core.windows.net\"\n",
    "\n",
    "# File share name\n",
    "share_name = \"intfileshare\"\n",
    "\n",
    "# Get a share client via connection string\n",
    "share_client = ShareServiceClient.from_connection_string(connection_string).get_share_client(share_name)\n",
    "\n",
    "# Source folder in the file share\n",
    "source_folder = \"sectra\"\n",
    "\n",
    "proj_dir = \"Evan Test_06acf4b09dab4043b8c1109b4e86c617\"\n",
    "\n",
    "# List all files and directories in the root of the file share\n",
    "print(\"Add DICOMDIR files to table:\")\n",
    "items = list(share_client.list_directories_and_files(f\"{source_folder}/{proj_dir}\"))\n",
    "for item in items:\n",
    "    if item[\"name\"] == \"DICOMDIR\":\n",
    "        subdirs = '.'\n",
    "    else:\n",
    "        subdirs = item['name']\n",
    "\n",
    "    print(item[\"name\"])\n",
    "    q = f\"\"\"\n",
    "        INSERT INTO 1_inland.sectra.pacs_file_copy (\n",
    "            src_root, src_proj_dir, src_subdirs, src_filename,\n",
    "            dst_filepath, active_ind, status, added_at\n",
    "        )\n",
    "        VALUES (\n",
    "            '{source_folder}', '{proj_dir}', '{subdirs}', 'DICOMDIR',\n",
    "            'test_dst_path', 0, 'new', CURRENT_TIMESTAMP()\n",
    "        );          \n",
    "    \"\"\"\n",
    "    spark.sql(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18ef1202-6f26-43ce-b6f7-89b25c3778b7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_client = share_client.get_file_client(f\"{source_folder}/{proj_dir}/DICOMDIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7254b6aa-7bca-4650-8fe4-968f127ee785",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "file_bytes = file_client.download_file().readall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50ebef13-bead-4d8c-9b12-c4554ffd45b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/Volumes/1_inland/sectra/vone/DICOMDIR\", \"wb\") as f:\n",
    "    f.write(file_bytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41f78dc2-9e32-4b01-b0dc-edfcd3fc42b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dcm_file = pydicom.dcmread(\"/Volumes/1_inland/sectra/vone/DICOMDIR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ce33e80-f99e-401f-8a93-f0c25a0148c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list(dcm_file.DirectoryRecordSequence[3][\"ReferencedFileID\"].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f0e0a06-e9d4-4fc6-91a6-aa9a157d9e3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "# Define the whole schema within a StructType\n",
    "schema = T.StructType([\n",
    "        T.StructField(\"src_subdirs\", T.StringType(), True),\n",
    "        T.StructField(\"src_file\", T.StringType(), True),\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(data = [], schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cbe13a7-86d6-42ad-96a1-6b1cca8d0786",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for x in tqdm.tqdm(dcm_file.DirectoryRecordSequence):\n",
    "    try:\n",
    "        refFileID = x[\"ReferencedFileID\"].value\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    new_row = spark.createDataFrame(\n",
    "        data=[(f\"{refFileID[1]}/{refFileID[2]}\", refFileID[3])],\n",
    "        schema=schema\n",
    "    )\n",
    "    \n",
    "    df = df.union(new_row)\n",
    "\n",
    "#del dcm_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb17f1e2-d486-4425-b4c8-28ee7c34a3e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "df = df.withColumn(\"dst_filepath\", F.concat(F.lit(f\"/Volumes/1_inland/sectra/vone/{proj_dir.replace(' ', '_')}/\"), F.col(\"src_subdirs\"), F.lit(\"/\"), F.col(\"src_file\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "59fde739-2231-44d1-b1b7-93f1c05bea86",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"temp_new_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6881ad88-e8c5-495e-9a8c-c18aa2e5cac9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "INSERT INTO 1_inland.sectra.pacs_file_copy\n",
    "(src_root, src_proj_dir, src_subdirs, src_filename,\n",
    "dst_filepath, active_ind, status, added_at)\n",
    "SELECT\n",
    "'{source_folder}','{proj_dir}',src_subdirs, src_file,\n",
    "dst_filepath, 1, 'new', current_timestamp()\n",
    "FROM temp_new_files\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4538028075438869,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "CopyImageFilesFromFileShareToVolume",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
